{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {},
   "source": [
    "# RAG Post Retrieval Optimization - Reranking featuring Bedrock and llamaindex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e",
   "metadata": {},
   "source": [
    "Reranking is a crucial post-retrieval process that refines the initial set of retrieved documents to improve the relevance and quality of information used for generating responses. After the initial retrieval step, which typically uses methods like vector similarity search, reranking takes the retrieved documents and re-scores their relevance to the query using more sophisticated techniques. These may include cross-encoders, BERT-based models, or other advanced algorithms that can better capture semantic nuances and context. Based on these scores, the documents are reordered, pushing the most relevant and informative ones to the top, thereby enhancing the accuracy and contextual appropriateness of the final response.\n",
    "\n",
    "In this lab, we will highlight the usage of an existing LLM (for example Bedrock Claude3 Haiku) as a reranker model to improve the relevance of the documents retrieved from Amazon SEC filings. We also utilized the Bedrock Claude-3 Sonnet model and the Bedrock Titan Text Embedding v2.0 model for natural language processing and document embeddings to build this RAG system. The key steps were: ingesting PDF documents into a vector database index, retrieving top relevant nodes based on a query using semantic search, reranking the retrieved nodes using the fine-tuned transformer model deployed on SageMaker, and synthesizing a final response consolidating the reranked information. See below image for details.\n",
    "\n",
    "- Vector Database (Faiss / local on the notebook for this demo)\n",
    "- LLM (Amazon Bedrock - Claude3 Sonnet)\n",
    "- Embeddings Model (Bedrock Titan Text Embedding v2.0)\n",
    "- ReRanking Model (Claude Haiku) running on Bedrock\n",
    "- Llamaindex for orchestration (ingestion, reranking, retrieval and final response synthesis)\n",
    "- Datasets (Amazon SEC 10-k statements for year 2022 and 2023 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94913f2-fca9-42e7-907a-a2c8c43f4897",
   "metadata": {},
   "source": [
    "<img src=\"reranking-bedrock.png\" width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b292497-3925-4977-9746-406d0e2062b6",
   "metadata": {},
   "source": [
    "## Pre-req\n",
    "You must run the `[workshop_setup.ipynb]`(../lab00-setup/workshop_setup.ipynb) notebook in `lab00-setup` before starting this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca62b6-2850-4293-a6fe-de90798611bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.warn(\"Warning: if you did not run lab00-setup, please go back and run the lab00 notebook\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af8379",
   "metadata": {},
   "source": [
    "\n",
    "### > Setup\n",
    "We start by importing necessary llamaindex libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebb89a-58e0-4fa0-ba8c-fdceb8f09d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf69a3",
   "metadata": {},
   "source": [
    "We select Anthropic Claude3 Sonnet as our LLM. For embedding model, we are selecting Amazon Titan Text Embed v2.0. Chunk size is set at 512 for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47283b-025e-4874-88ed-76245b22f82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    "from llama_index.llms.bedrock import Bedrock\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding, Models\n",
    "\n",
    "llm = Bedrock(model = \"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "embed_model = BedrockEmbedding(model = \"amazon.titan-embed-text-v2:0\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21029523",
   "metadata": {},
   "source": [
    "### > Document Ingestion\n",
    "We ingest and index the data stored in data directory. The amazon folder has SEC-10k files from 2022 and 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16457565-4547-4655-a695-6e468286bf56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "amazon_secfiles = SimpleDirectoryReader(input_dir=\"../data/lab03/amazon/\").load_data()\n",
    "\n",
    "# build index\n",
    "amazon_index = VectorStoreIndex.from_documents(\n",
    "    amazon_secfiles,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1be2e",
   "metadata": {},
   "source": [
    "### > Helper functions\n",
    "Helper functions to help retrieve and visualize relevant nodes from vector database based on a given query. It allows for optional reranking of results using a language model (in this case, Claude 3 Haiku). The retrieved nodes are then displayed in a formatted HTML table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c5e35-1651-4041-8e05-93da28d855f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core import QueryBundle\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def get_retrieved_nodes(\n",
    "    query_str, vector_top_k=5, reranker_top_n=3, with_reranker=False\n",
    "):\n",
    "    query_bundle = QueryBundle(query_str)\n",
    "    # configure retriever\n",
    "    retriever = VectorIndexRetriever(\n",
    "        index=amazon_index,\n",
    "        similarity_top_k=vector_top_k,\n",
    "    )\n",
    "    retrieved_nodes = retriever.retrieve(query_bundle)\n",
    "\n",
    "    if with_reranker:\n",
    "        # configure reranker\n",
    "        reranker = RankGPTRerank(\n",
    "            llm=Bedrock(model = \"anthropic.claude-3-haiku-20240307-v1:0\"),\n",
    "            top_n=reranker_top_n,\n",
    "            verbose=True,\n",
    "        )\n",
    "        retrieved_nodes = reranker.postprocess_nodes(\n",
    "            retrieved_nodes, query_bundle\n",
    "        )\n",
    "\n",
    "    return retrieved_nodes\n",
    "\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display(HTML(df.to_html().replace(\"\\\\n\", \"\")))\n",
    "\n",
    "\n",
    "def visualize_retrieved_nodes(nodes) -> None:\n",
    "    result_dicts = []\n",
    "    for node in nodes:\n",
    "        result_dict = {\"Score\": node.score, \"Text\": node.node.get_text()}\n",
    "        result_dicts.append(result_dict)\n",
    "\n",
    "    pretty_print(pd.DataFrame(result_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4ad8e8-c61b-4580-89cf-b2247d2f4c30",
   "metadata": {},
   "source": [
    "### > Test retrieval without reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed1c76a-3f47-4007-a086-53956f573c00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_nodes = get_retrieved_nodes(\n",
    "    \"Describe key business risks for Amazon during covid\",\n",
    "    vector_top_k=10,\n",
    "    with_reranker=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e5e94-f0c0-4eab-8956-b0c7d0e67b58",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_retrieved_nodes(new_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d279da8-064f-4a48-aa1e-37f32bc1f848",
   "metadata": {},
   "source": [
    "### > Add reranking\n",
    "We will use a llamaIndex module called `RankGPTRerank`. This is a zero-shot listwise passage reranking method that uses large language models (Anthropic Claude 3 Haiku) to efficiently reorder retrieved passages based on their relevance to a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999cace-5f53-4187-9319-6c168858b5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.rankgpt_rerank import RankGPTRerank\n",
    "\n",
    "new_nodes = get_retrieved_nodes(\n",
    "    \"Describe key business risks for Amazon during covid\",\n",
    "    vector_top_k=10,\n",
    "    reranker_top_n=5,\n",
    "    with_reranker=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7a558-9ec8-40b5-b31a-5fbb0136751f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_retrieved_nodes(new_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa36afb-0998-4679-8bf2-98c63b18f947",
   "metadata": {},
   "source": [
    "### > Apply reranking to final response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da37a97-e610-4989-b43d-c31abe3d2347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine_naive = amazon_index.as_query_engine(similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c49cb9f-33fc-4f6f-8d41-cc900dd12ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine_naive.query(\n",
    "    \"Describe key business risks for Amazon during covid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b3b55-cd6f-48f3-a1ee-5057cde3752f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reranker = RankGPTRerank(\n",
    "            llm=Bedrock(model = \"anthropic.claude-3-haiku-20240307-v1:0\"),\n",
    "            top_n=5,\n",
    "            verbose=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c96b91-a4be-42bc-9616-6caa9c24ab6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine_rerank = amazon_index.as_query_engine(similarity_top_k=10, node_postprocessor =[reranker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff672d3-d93d-4933-a6eb-d27702a97e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine_rerank.query(\n",
    "    \"Describe key business risks for Amazon during covid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b984ca-21b0-4321-bba2-a5a60fdd82c2",
   "metadata": {},
   "source": [
    "### > Final reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83771aef-4d54-48a8-b393-d1691c414fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd1d956-cee2-4345-8de1-7e1ec91f011b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
