{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {},
   "source": [
    "# RAG Post Retrieval Optimization - Reranking featuring Bedrock and llamaindex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e",
   "metadata": {},
   "source": [
    "Reranking is a crucial post-retrieval process that refines the initial set of retrieved documents to improve the relevance and quality of information used for generating responses. After the initial retrieval step, which typically uses methods like vector similarity search, reranking takes the retrieved documents and re-scores their relevance to the query using more sophisticated techniques. These may include cross-encoders, BERT-based models, or other advanced algorithms that can better capture semantic nuances and context. Based on these scores, the documents are reordered, pushing the most relevant and informative ones to the top, thereby enhancing the accuracy and contextual appropriateness of the final response.\n",
    "\n",
    "In this lab, we will highlight the usage of Bedrock Reranker LLMs (for example Cohere Rerank 3.5) as a reranker model to improve the relevance of the documents retrieved from Amazon SEC filings. We also utilized the Bedrock Nova Pro model and the Bedrock Titan Text Embedding v2.0 model for natural language processing and document embeddings to build this RAG system. The key steps were: ingesting PDF documents into a vector database index, retrieving top relevant nodes based on a query using semantic search, reranking the retrieved nodes using the fine-tuned transformer model deployed on SageMaker, and synthesizing a final response consolidating the reranked information. See below image for details.\n",
    "\n",
    "- Vector Database (Faiss / local on the notebook for this demo)\n",
    "- LLM (Amazon Bedrock - Nova Pro)\n",
    "- Embeddings Model (Bedrock Titan Text Embedding v2.0)\n",
    "- ReRanking Model (Cohere Reranker 3.5) running on Bedrock\n",
    "- Llamaindex for orchestration (ingestion, reranking, retrieval and final response synthesis)\n",
    "- Datasets (Amazon SEC 10-k statements for year 2022 and 2023 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b292497-3925-4977-9746-406d0e2062b6",
   "metadata": {},
   "source": [
    "## Pre-req\n",
    "You must run the `[workshop_setup.ipynb]`(../lab00-setup/workshop_setup.ipynb) notebook in `lab00-setup` before starting this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca62b6-2850-4293-a6fe-de90798611bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.warn(\"Warning: if you did not run lab00-setup, please go back and run the lab00 notebook\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1118dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the config content\n",
    "config_content = \"\"\"[profile default]\n",
    "region = us-west-2\n",
    "output = json\n",
    "\"\"\"\n",
    "\n",
    "# Get the path to the .aws directory and config file\n",
    "home_dir = \"/home/sagemaker-user\"  # SageMaker specific path\n",
    "aws_dir = os.path.join(home_dir, \".aws\")\n",
    "config_path = os.path.join(aws_dir, \"config\")\n",
    "\n",
    "# Check if config file already exists\n",
    "if os.path.exists(config_path):\n",
    "    print(f\"AWS config file already exists at {config_path}. No changes made.\")\n",
    "else:\n",
    "    # Create the .aws directory if it doesn't exist\n",
    "    os.makedirs(aws_dir, exist_ok=True)\n",
    "    \n",
    "    # Create the config file with the content\n",
    "    with open(config_path, \"w\") as f:\n",
    "        f.write(config_content + \"\\n\")\n",
    "    \n",
    "    print(f\"Created directory {aws_dir} and created AWS config file at {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af8379",
   "metadata": {},
   "source": [
    "\n",
    "### > Setup\n",
    "We start by importing necessary llamaindex libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebb89a-58e0-4fa0-ba8c-fdceb8f09d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf69a3",
   "metadata": {},
   "source": [
    "We select Anthropic Claude3 Sonnet as our LLM. For embedding model, we are selecting Amazon Titan Text Embed v2.0. Chunk size is set at 512 for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47283b-025e-4874-88ed-76245b22f82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding, Models\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "#from llama_index.core.postprocessor.bedrock_rerank import AWSBedrockRerank\n",
    "\n",
    "profile_name = \"default\"\n",
    "\n",
    "# define the LLM\n",
    "llm = BedrockConverse(\n",
    "    model=\"us.amazon.nova-pro-v1:0\",\n",
    "    profile_name=profile_name,\n",
    ")\n",
    "\n",
    "# define the embedding model\n",
    "embed_model = BedrockEmbedding(model = \"amazon.titan-embed-text-v2:0\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21029523",
   "metadata": {},
   "source": [
    "### > Document Ingestion\n",
    "We ingest and index the data stored in data directory. The amazon folder has SEC-10k files from 2022 and 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16457565-4547-4655-a695-6e468286bf56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "amazon_secfiles = SimpleDirectoryReader(input_dir=\"../data/lab03/amazon/\").load_data()\n",
    "\n",
    "# build index\n",
    "amazon_index = VectorStoreIndex.from_documents(\n",
    "    amazon_secfiles,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19cdaa6-6dc9-4ecb-9022-722086575612",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = amazon_index.as_query_engine(similarity_top_k=5)\n",
    "response = query_engine.query(\n",
    "    \"Describe key business risks for Amazon during covid?\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d5a7c8-6ae1-4b0e-9482-92e2afd60606",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.source_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd870f6d-39c8-45aa-bae3-a473b1561b60",
   "metadata": {},
   "source": [
    "# Using Bedrock Rerank LLMs with Llamaindex. We will try with Cohere Reranker3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968fc306-2386-4df0-940d-f156f000ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.postprocessor.bedrock_rerank import AWSBedrockRerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c23440-bb7e-4d1e-888e-cfe1472ce6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = AWSBedrockRerank(\n",
    "    top_n=3,\n",
    "    model_id=\"cohere.rerank-v3-5:0\",\n",
    "    region_name=\"us-west-2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f9a100-6445-4fa4-be4f-e873ab4bc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = amazon_index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    node_postprocessors=[reranker],\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"Describe key business risks for Amazon during covid?\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3897d-30e5-41c0-9829-687d7f0e7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23343f2d-7b50-4098-9900-08233e992f91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
