{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {},
   "source": [
    "# RAG Retrieval Optimization - Query Transformation (Hyde) using Amazon Bedrock and Llamaindex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e",
   "metadata": {},
   "source": [
    "HyDE is a special type of query transformation technique that enhances the retrieval process and improve the relevance of retrieved documents. Instead of directly using the original query for retrieval, HyDE leverages a language model to generate a hypothetical document that captures the essence of the query's intent. This hypothetical document is then converted into an embedding, which is used to search for similar real documents in the knowledge base. The underlying concept is that the hypothetical document may be closer in the embedding space to relevant information than the original query itself, potentially leading to more accurate and contextually appropriate retrievals. HyDE has shown promising results in improving RAG performance, especially in zero-shot, and it has demonstrated effectiveness across various languages and tasks.\n",
    "\n",
    "\n",
    "This example is built on referece llamaindex [documentation](https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/query_transformations/HyDEQueryTransformDemo.ipynb)\n",
    "\n",
    "Here are the components we used:Here are the components we used:\n",
    "\n",
    "- Vector Database (Faiss / local)\n",
    "- LLM (Amazon Bedrock - Claude3 Sonnet)\n",
    "- Embeddings Model (Bedrock Titan Text Embedding v2.0)\n",
    "- Datasets ( Amazons SEC-10k statments )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f626ffe1-9481-4c45-b62f-6cae8c82cee1",
   "metadata": {},
   "source": [
    "## Pre-req\n",
    "You must run the `[workshop_setup.ipynb]`(../lab00-setup/workshop_setup.ipynb) notebook in `lab00-setup` before starting this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebe1e0-1fc4-462e-a26e-9124bbf243e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.warn(\"Warning: if you did not run lab00-setup, please go back and run the lab00 notebook\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67af8141",
   "metadata": {},
   "source": [
    "### > Setup\n",
    "\n",
    "We start by importing necessary llamaindex libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebb89a-58e0-4fa0-ba8c-fdceb8f09d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f480f4-10cb-4578-88d7-7b3641931cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "\n",
    "# Set your AWS profile name\n",
    "profile_name = \"default\"\n",
    "\n",
    "# Simple completion call\n",
    "resp = BedrockConverse(\n",
    "    model=\"us.amazon.nova-pro-v1:0\",\n",
    "    profile_name=profile_name,\n",
    ").complete(\"Paul Graham is \")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05622867",
   "metadata": {},
   "source": [
    "We select Anthropic Claude3 Sonnet as our LLM. For embedding model, we are selecting Amazon Titan Text Embed v2.0. Chunk size is set at 128 for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47283b-025e-4874-88ed-76245b22f82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.llms.bedrock_converse import BedrockConverse\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding, Models\n",
    "\n",
    "profile_name = \"default\"\n",
    "\n",
    "# define the LLM\n",
    "llm = BedrockConverse(\n",
    "    model=\"us.amazon.nova-pro-v1:0\",\n",
    "    profile_name=profile_name,\n",
    ")\n",
    "\n",
    "# define the embedding model\n",
    "embed_model = BedrockEmbedding(model = \"amazon.titan-embed-text-v2:0\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c98e58",
   "metadata": {},
   "source": [
    "We ingest and index the data stored in data directory. The amazon folder has SEC-10k files from 2022 and 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edde11c-3484-4e21-9be8-56a2ba0ef2a3",
   "metadata": {},
   "source": [
    "### > Document Ingestion\n",
    "\n",
    "We ingest the documents and use [Titan Text Embeddings v2.0 model](https://docs.aws.amazon.com/bedrock/latest/userguide/titan-embedding-models.html) to create the embedding for each document chunk. The amazon folder has SEC-10k files from 2022 and 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16457565-4547-4655-a695-6e468286bf56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "amazon_secfiles = SimpleDirectoryReader(input_dir=\"../data/lab03/amazon/\").load_data()\n",
    "\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    amazon_secfiles,\n",
    "    use_async=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7c5381-b064-42a3-a6c7-7d3aeba425e2",
   "metadata": {},
   "source": [
    "Define the query engine from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826956e5-2206-4ba0-8aeb-beafa9a284b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine(\n",
    "    top_k=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9765c51e-00b5-4ce9-93b4-5d321ca770e0",
   "metadata": {},
   "source": [
    "### > Test Using Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f414cda3-8a56-44a8-96a8-522c0f0e10b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"How may Covid impact Amazon's business model and financial outlook over the next decade?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aef3a8-1ae8-4d63-8451-8c78e942f572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_response = query_engine.query(query)\n",
    "print(colored(raw_response, \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e2a6a",
   "metadata": {},
   "source": [
    "### > Test Using HyDEQueryTransform to generate Hypothetical \n",
    "\n",
    "`HyDEQueryTransform` is a llamaIndex module that uses a language model to generate a hypothetical document based on the query, which is then embedded and used for similarity search to retrieve relevant documents, potentially improving retrieval accuracy in RAG systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74d861-a412-4b59-81c3-51c27120229b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyde = HyDEQueryTransform(include_original=True)\n",
    "hyde_query_engine = TransformQueryEngine(query_engine, hyde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7462c1-bfd9-4e24-b3c0-b3211ecb766e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "hyde_response = hyde_query_engine.query(query)\n",
    "print(colored(hyde_response, \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1aedc7-0f12-4f6c-8ac3-46a0f72a7a34",
   "metadata": {},
   "source": [
    "Here is the the hypothetic answer generated by HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fbdad-54dc-4289-8a92-0be3db1aa72e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_bundle = hyde(query)\n",
    "hyde_doc = query_bundle.embedding_strs[0]\n",
    "print(colored(hyde_doc, \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f417e1-1c39-4f94-848d-d5fe42e2191d",
   "metadata": {},
   "source": [
    "### > Display the results side-by-side \n",
    "\n",
    "Notice the Hypothetic response generated by HyDE help much retrieve context that are more focused on Amazon's business model and financial outlook instead of other info that are less relevant to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dbdfaa-ee3b-458c-baf8-df5cae26865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the first table\n",
    "df = pd.DataFrame({\n",
    "    'Naive RAG': [query, raw_response],\n",
    "    'RAG w/ HyDE': [query, hyde_response]\n",
    "})\n",
    "\n",
    "output=\"\"\n",
    "output += df.style.hide().set_table_attributes(\"style='display:inline'\")._repr_html_()\n",
    "output += \"&nbsp;\"\n",
    "\n",
    "display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61c9cd-1412-4d21-9551-deb1e2e4f7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
