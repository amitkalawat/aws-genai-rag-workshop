{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {},
   "source": [
    "# RAG Retrieval Optimization - Sentence Window Parsing technique with Amazon Bedrock and Llamaindex\n",
    "\n",
    "### Small to big retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673df1fe-eb6c-46ea-9a73-a96e7ae7942e",
   "metadata": {},
   "source": [
    "Sentence window is another technique that enhances the retrieval process by focusing on individual sentences while providing surrounding context. In this approach, documents are parsed into single sentences, each with a \"window\" of surrounding sentences. During retrieval, the system finds the most relevant individual sentences. However, instead of using only these single sentences, it replaces them with their corresponding windows, which include a specified number of sentences before and after the retrieved sentence. This method allows for more fine-grained retrieval of specific information while still providing necessary context, potentially improving the relevance and coherence of the generated responses.\n",
    "\n",
    "In this lab, we demonstrated how to use sentence window technique for post-retrieval with LlamaIndex. Specifically, we employed the SentenceWindowNodeParser module to splits Amazon's SEC filing documents into individual sentences, creating a node for each sentence while also including a configurable \"window\" of surrounding sentences in the node's metadata. We can then use the MetadataReplacementPostProcessor module to retrieve the sentence along with associated 'window' metadata to improve the context for final response generation.\n",
    "\n",
    "- Vector Database (Faiss / local)\n",
    "- LLM (Amazon Bedrock - Claude3 Sonnet)\n",
    "- Embeddings Model (Bedrock Titan Text Embeddings v2.0)\n",
    "- Datasets ( Amazons 10-k sec filings from year 2022 and 2023 )\n",
    "- Llamaindex SentenceWindowNodeParser (This example is built on referece llamaindex documentation available at - https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/MetadataReplacementDemo/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff000c3a",
   "metadata": {},
   "source": [
    "### > Setup\n",
    "We start by importing necessary llamaindex libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebb89a-58e0-4fa0-ba8c-fdceb8f09d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
    "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99781aad",
   "metadata": {},
   "source": [
    "We select Anthropic Claude3 Sonnet as our LLM. For embedding model, we are selecting Amazon Titan Text Embed v2.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47283b-025e-4874-88ed-76245b22f82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, List\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.llms.bedrock import Bedrock\n",
    "from llama_index.embeddings.bedrock import BedrockEmbedding, Models\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")\n",
    "\n",
    "# base node parser is a sentence splitter\n",
    "text_splitter = SentenceSplitter()\n",
    "\n",
    "llm = Bedrock(model = \"anthropic.claude-3-sonnet-20240229-v1:0\")\n",
    "embed_model = BedrockEmbedding(model = \"amazon.titan-embed-text-v2:0\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 256\n",
    "Settings.text_splitter = text_splitter\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core.tools import BaseTool, FunctionTool\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf99898",
   "metadata": {},
   "source": [
    "### > Document Ingestion\n",
    "We ingest and index the data stored in data directory. The amazon folder has SEC-10k files from 2022 and 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cf76d-0358-4a8a-8803-a09a99d93763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "amazon_secfiles = SimpleDirectoryReader(input_dir=\"../data/lab03/amazon/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f1449-f3e3-47a0-b763-a8baf3ae8e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(amazon_secfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24bb0e-d36b-4dfe-8f17-9058b06fae4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_nodes = text_splitter.get_nodes_from_documents(amazon_secfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a526e-7779-44ad-a49d-38f161513f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "sentence_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f31b8-df4e-4e4b-94b2-a56493c90e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_index = VectorStoreIndex(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94f2ab-4daa-4d76-8ae0-1762c59512a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    # the target key defaults to `window` to match the node_parser's default\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ],\n",
    ")\n",
    "window_response = query_engine.query(\n",
    "    \"Whats Amazons ownership stake in Rivian??\"\n",
    ")\n",
    "print(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1984a-d92e-415f-ac7a-3ba306ddebe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "window = window_response.source_nodes[0].node.metadata[\"window\"]\n",
    "sentence = window_response.source_nodes[0].node.metadata[\"original_text\"]\n",
    "\n",
    "print(f\"Window: {window}\")\n",
    "print(\"------------------\")\n",
    "print(f\"Original Sentence: {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd31ac-b7b5-4bd9-9d8c-be41a0ca9374",
   "metadata": {},
   "source": [
    "# Contrast with normal VectorStoreIndex\n",
    "\n",
    "Naive RAG is not able to pinpoint necessary details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e49fc-1d9f-4113-8f6f-14bb020ad14f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = base_index.as_query_engine(similarity_top_k=2)\n",
    "vector_response = query_engine.query(\n",
    "    \"Whats Amazons ownership stake in Rivian?\"\n",
    ")\n",
    "print(vector_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924921f-1f14-417e-83ab-1f0d10cd7dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for source_node in window_response.source_nodes:\n",
    "    print(source_node.node.metadata[\"original_text\"])\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e01c4-0395-4f7a-ab50-f9b42d091e62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for node in vector_response.source_nodes:\n",
    "    print(node.node.text)\n",
    "    print(\"--------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
