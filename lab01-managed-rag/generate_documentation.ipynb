{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea63fcab-4682-4c5a-9891-45e62c6d0854",
   "metadata": {},
   "source": [
    "## Managed RAG Lab\n",
    "\n",
    "In this lab, we will build a technical documentation assistant using Amazon Q Business to help developers find and answer questions about Swagger APIs, also known as the OpenAPI Specification, which provides a standardized way to describe APIs.\n",
    "\n",
    "In this situation, the Swagger API documentation consists of JSON or YAML files, flow diagrams, and other non-rich text formats. Amazon Q Business does not handle these data types by default, therefore we will need to run an enrichment process using this notebook to generate synthetic documentation based on YAML files and images for Amazon Q for Business. Here is a flow diagram of this lab:\n",
    "\n",
    "\n",
    "![Lab Diagram](../static/q-business.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3ae27-9d02-4815-931b-b7e17250e691",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea2376-a35a-4ec0-9455-5753ed0cc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    get_text_response,\n",
    "    load_yaml_to_string,\n",
    "    upload_file_to_s3,\n",
    "    image_to_base64\n",
    ")\n",
    "from termcolor import colored\n",
    "import json\n",
    "import sagemaker\n",
    "import os\n",
    "import time\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "region = sagemaker_session._region_name\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"swagger_codegen\"\n",
    "\n",
    "# claude pricing in us-east-1 pricing\n",
    "input_per_1k = 0.00025\n",
    "output_per_1k = 0.00125\n",
    "\n",
    "data_dir = \"../data\"\n",
    "yml_dir = f\"{data_dir}/yml_files\"\n",
    "uml_dir = f\"{data_dir}/uml_diagrams\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1becb1e5-2ca0-4751-a0f6-938b019c520f",
   "metadata": {},
   "source": [
    "### > Enrich the yml files\n",
    "\n",
    "Here is a prompt for Anthropic Claude3 model to generate synthetic documentation from YAML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e37c9-b7ef-4ae7-b639-82f138de0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "You will be provided with an OpenAPI YAML file containing the specification for a set of APIs. Your\n",
    "task is to generate a principle-level documentation for these APIs in JSON format.\n",
    "\n",
    "Here are the steps you should follow:\n",
    "\n",
    "1. Read the provided <yaml> carefully and understand the APIs, their\n",
    "endpoints, request/response data structures, and other details.\n",
    "\n",
    "<yaml>\n",
    "{YAML_FILE}\n",
    "</yaml>\n",
    "\n",
    "2. In the <description> field of your JSON output, provide a comprehensive description of the APIs.\n",
    "Explain what each API does, what data properties the requests take, and what the expected response\n",
    "messages are. Callout any limits and frequent encoutered errors. Useexamples from the YAML file to \n",
    "illustrate your points.\n",
    "\n",
    "3. In the <stats> field, generate some overall statistics about the APIs and present them in pullet\n",
    "list sentence style, such as:\n",
    "- Number of routes/endpoints?\n",
    "- Number of request data models?\n",
    "- Number of response data models?\n",
    "- Any other relevant stats you can extract from the YAML file\n",
    "\n",
    "4. In the <faq> field, generate a list of 20 questions and corresponding answers for a Frequently Asked\n",
    "Questions (FAQ) section. Start with simple questions about the APIs and gradually increase the\n",
    "complexity. The questions should cover various aspects of the APIs, such as their functionality,\n",
    "data structures, error handling, and so on. The answers should be clear, concise, and informative,\n",
    "using examples from the YAML file where appropriate.\n",
    "\n",
    "5. Structure your JSON output as follows:\n",
    "\n",
    "{\n",
    "\"description\": \"<description>\",\n",
    "\"stats\": \"<stats>\",\n",
    "\"faq\": [\n",
    "{\n",
    "\"question\": \"<question>\",\n",
    "\"answer\": \"<answer>\"\n",
    "},\n",
    "...\n",
    "]\n",
    "}\n",
    "\n",
    "Replace <description>, <stats>, <question>, and <answer> with the appropriate content you generated\n",
    "in the previous steps.\n",
    "\n",
    "Please provide your response in JSON format only, without any additional explanations or comments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000faaeb-387e-47ce-9c05-b010e3af330e",
   "metadata": {},
   "source": [
    "### > Let's preview one of the YAML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87597fbc-2fcc-4862-b7e9-87bc9015b16f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "yml_file = f\"{data_dir}/yml_files/petstore.yml\"\n",
    "yml_str = load_yaml_to_string(yml_file)\n",
    "\n",
    "\n",
    "display(Markdown(f\"\"\"```yml\\n{yml_str}```\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e55157-1dfe-4339-9057-9aaf30e5f7e8",
   "metadata": {},
   "source": [
    "### > Generate enriched documents from YAML\n",
    "\n",
    "This code snippet below is processing YAML files (which contain Swagger API documentation) to generate human-readable documentation in text format. This documentation can then be leveraged by Amazon Q Business to buils an AI assistant that understand these APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2928e-52a7-4e6d-965b-7e6a60bb50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0819fb1-2796-4fa7-8328-6fa8507f96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "\n",
    "for yml_filename in os.listdir(yml_dir):\n",
    "    # Construct the full file path\n",
    "    yml_filepath = os.path.join(yml_dir, yml_filename)\n",
    "\n",
    "    yml_str = load_yaml_to_string(yml_filepath)\n",
    "\n",
    "    query = prompt_template.replace(\"{YAML_FILE}\", yml_str)\n",
    "\n",
    "    max_retries = 3\n",
    "    delay = 2  # Delay in seconds between retries\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "    \n",
    "            response = get_text_response(text_query=query)\n",
    "            \n",
    "            input_tokens += response[\"usage\"][\"input_tokens\"]\n",
    "            output_tokens += response[\"usage\"][\"output_tokens\"]\n",
    "            \n",
    "            document_json = json.loads(response[\"content\"][0][\"text\"])\n",
    "            print(\"JSON loaded successfully...\\n\")\n",
    "            break\n",
    "        except json.JSONDecodeError as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"Failed to load JSON after {max_retries} attempts. Skipping operation.\\n\")\n",
    "            else:\n",
    "                print(f\"Failed to load JSON (attempt {attempt + 1}/{max_retries}): {e}\\n\")\n",
    "                time.sleep(delay)\n",
    "                \n",
    "    # yml upload file to s3\n",
    "    key = f\"{prefix}/{yml_filepath.replace(data_dir+'/', '')}\"\n",
    "    s3_path = upload_file_to_s3(yml_filepath, bucket, key)\n",
    "    \n",
    "    print(f'yml file uploaded to {s3_path}...\\n')\n",
    "    \n",
    "    # build the doc\n",
    "    doc = f\"\"\"\n",
    "    Documentation for {yml_filename.split(\".\")[0]}\n",
    "    \n",
    "    Description:\n",
    "    {document_json[\"description\"]}\n",
    "    {document_json[\"stats\"]}\n",
    "    \n",
    "    FAQ:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for faq in document_json[\"faq\"]:\n",
    "        doc += faq[\"question\"] + \"\\n\\n\" + faq[\"answer\"] + \"\\n\\n\"\n",
    "        \n",
    "    txt_filename = yml_filename.split(\".\")[0]+\".txt\"\n",
    "    txt_filepath = f\"{data_dir}/yml_questions/{txt_filename}\"\n",
    "    \n",
    "    with open(txt_filepath, 'w', encoding='utf-8') as file:\n",
    "                file.write(doc)\n",
    "    print(f'documentation generated at {txt_filepath}...\\n')\n",
    "    \n",
    "    # txt file upload file to s3\n",
    "    key = f\"{prefix}/{txt_filepath.replace(data_dir+'/', '')}\"\n",
    "    metadata = {\"s3_url\":s3_path}\n",
    "    s3_path = upload_file_to_s3(txt_filepath, bucket, key, metadata=metadata)\n",
    "    \n",
    "    print(f'documentation uploaded to {s3_path}...\\n')\n",
    "    \n",
    "total_cost = (\n",
    "    input_per_1k * input_tokens +\n",
    "    output_per_1k * output_tokens\n",
    ") / 1000\n",
    "\n",
    "print('\\n')\n",
    "print('========================================================================')\n",
    "print('Estimated cost:', colored(f\"${total_cost}\", 'green'), f\"in us-east-1 region with {colored(input_tokens, 'green')} input tokens and {colored(output_tokens, 'green')} output tokens.\")\n",
    "print('========================================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bee0c-230c-43b1-993a-cb7001ea2069",
   "metadata": {},
   "source": [
    "### > Enrich UML diagrams\n",
    "\n",
    "Here is a prompt for Anthropic Claude3 model to generate synthetic caption from UML diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e59d4b9-e51a-4819-bb56-a2c423e4d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "You will be provided with an OpenAPI YAML file containing the specification for a set of APIs. Your\n",
    "task is to generate a principle-level documentation for these APIs in JSON format.\n",
    "\n",
    "Here are the steps you should follow:\n",
    "\n",
    "1. Read the provided images carefully to understand the APIs, their\n",
    "endpoints, request/response data structures, and other details.\n",
    "\n",
    "2. In the <description> field of your JSON output, provide a comprehensive description of the APIs.\n",
    "Explain what each API does, what data properties the requests take, and what the expected response\n",
    "messages are. Callout any limits and frequent encoutered errors. Useexamples from the YAML file to \n",
    "illustrate your points.\n",
    "\n",
    "3. In the <stats> field, generate some overall statistics about the APIs and present them in pullet\n",
    "list sentence style, such as:\n",
    "- Number of routes/endpoints?\n",
    "- Number of request data models?\n",
    "- Number of response data models?\n",
    "- Any other relevant stats you can extract from the YAML file\n",
    "\n",
    "4. In the <faq> field, generate a list of 20 questions and corresponding answers for a Frequently Asked\n",
    "Questions (FAQ) section. Start with simple questions about the APIs and gradually increase the\n",
    "complexity. The questions should cover various aspects of the APIs, such as their functionality,\n",
    "data structures, error handling, and so on. The answers should be clear, concise, and informative,\n",
    "using examples from the YAML file where appropriate.\n",
    "\n",
    "5. Structure your JSON output as follows:\n",
    "\n",
    "{\n",
    "\"description\": \"<description>\",\n",
    "\"stats\": \"<stats>\",\n",
    "\"faq\": [\n",
    "{\n",
    "\"question\": \"<question>\",\n",
    "\"answer\": \"<answer>\"\n",
    "},\n",
    "...\n",
    "]\n",
    "}\n",
    "\n",
    "Replace <description>, <stats>, <question>, and <answer> with the appropriate content you generated\n",
    "in the previous steps.\n",
    "\n",
    "Please provide your response in JSON format only, without any additional explanations or comments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9388a9-657a-4c91-9432-8d827f481739",
   "metadata": {},
   "source": [
    "### > Let's preview one of the UML diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ce0d8d-ad94-4451-8723-f6df614286a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Open the JPG image file\n",
    "image = Image.open(f\"{data_dir}/uml_diagrams/petstore.jpg\")\n",
    "image = image.convert(\"RGB\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29376b9a-bd48-4a80-8c1d-8c4ebd2e46b0",
   "metadata": {},
   "source": [
    "### > Generate enriched documents from UML¶\n",
    "This code snippet below is processing UML diagrams (which contain Swagger API information) to generate human-readable documentation in text format. This documentation can then be leveraged by Amazon Q Business to buils an AI assistant that understand these APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d328e-ff37-476d-83b4-a983e7bdd04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf `find -type d -name .ipynb_checkpoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a1321-eaed-41c9-93b7-3ccdbabe742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "\n",
    "for uml_filename in os.listdir(uml_dir):\n",
    "    # Construct the full file path\n",
    "    uml_filepath = os.path.join(uml_dir, uml_filename)\n",
    "\n",
    "    image = Image.open(uml_filepath)\n",
    "    image = image.convert(\"RGB\")\n",
    "\n",
    "    query = prompt_template\n",
    "\n",
    "    max_retries = 3\n",
    "    delay = 2  # Delay in seconds between retries\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "    \n",
    "            response = get_text_response(image_base64=image_to_base64(image),text_query=query)\n",
    "            \n",
    "            input_tokens += response[\"usage\"][\"input_tokens\"]\n",
    "            output_tokens += response[\"usage\"][\"output_tokens\"]\n",
    "            \n",
    "            document_json = json.loads(response[\"content\"][0][\"text\"])\n",
    "            print(\"JSON loaded successfully...\\n\")\n",
    "            break\n",
    "        except json.JSONDecodeError as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"Failed to load JSON after {max_retries} attempts. Skipping operation.\\n\")\n",
    "            else:\n",
    "                print(f\"Failed to load JSON (attempt {attempt + 1}/{max_retries}): {e}\\n\")\n",
    "                time.sleep(delay)\n",
    "                \n",
    "    # yml upload file to s3\n",
    "    key = f\"{prefix}/{uml_filepath.replace(data_dir+'/', '')}\"\n",
    "    s3_path = upload_file_to_s3(uml_filepath, bucket, key)\n",
    "    \n",
    "    print(f'yml file uploaded to {s3_path}...\\n')\n",
    "    \n",
    "    # build the doc\n",
    "    doc = f\"\"\"\n",
    "    Documentation for {yml_filename.split(\".\")[0]}\n",
    "    \n",
    "    Description:\n",
    "    {document_json[\"description\"]}\n",
    "    {document_json[\"stats\"]}\n",
    "    \n",
    "    FAQ:\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for faq in document_json[\"faq\"]:\n",
    "        doc += faq[\"question\"] + \"\\n\\n\" + faq[\"answer\"] + \"\\n\\n\"\n",
    "        \n",
    "    txt_filename = uml_filename.split(\".\")[0]+\".txt\"\n",
    "    txt_filepath = f\"{data_dir}/uml_questions/{txt_filename}\"\n",
    "    \n",
    "    with open(txt_filepath, 'w', encoding='utf-8') as file:\n",
    "                file.write(doc)\n",
    "    print(f'documentation generated at {txt_filepath}...\\n')\n",
    "    \n",
    "    # txt file upload file to s3\n",
    "    key = f\"{prefix}/{txt_filepath.replace(data_dir+'/', '')}\"\n",
    "    metadata = {\"s3_url\":s3_path}\n",
    "    s3_path = upload_file_to_s3(txt_filepath, bucket, key, metadata=metadata)\n",
    "    \n",
    "    print(f'documentation uploaded to {s3_path}...\\n')\n",
    "    \n",
    "total_cost = (\n",
    "    input_per_1k * input_tokens +\n",
    "    output_per_1k * output_tokens\n",
    ") / 1000\n",
    "\n",
    "print('\\n')\n",
    "print('========================================================================')\n",
    "print('Estimated cost:', colored(f\"${total_cost}\", 'green'), f\"in us-east-1 region with {colored(input_tokens, 'green')} input tokens and {colored(output_tokens, 'green')} output tokens.\")\n",
    "print('========================================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba0498-b79b-40a0-af3f-a42f3c35158e",
   "metadata": {},
   "source": [
    "### > Store the parameter for future labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cec5b-d362-4377-8872-360c09e34632",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store bucket\n",
    "%store prefix\n",
    "%store yml_dir\n",
    "%store uml_dir\n",
    "%store data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93953950-5bd2-4e31-9e7a-673b90f77bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
